{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdce1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Imports and set platform\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "import numpy_indexed as npi\n",
    "import pandas as pd\n",
    "import platform\n",
    "import requests\n",
    "import scipy as sp\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "curr_comp = platform.node()\n",
    "curr_comp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac7e6dd",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22883a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in book data\n",
    "colnames = ['book_id','title','avg_rating','description']\n",
    "\n",
    "if curr_comp == 'DESKTOP-ARTEMI5' or curr_comp == 'Mandey-Lappy-Toppy':\n",
    "    orig_url='https://drive.google.com/file/d/15DvRQIdkXVg3qXVkyDm2GsgXVcTmgzYj/view?usp=sharing'\n",
    "    file_id = orig_url.split('/')[-2]\n",
    "    dwn_url='https://drive.google.com/uc?export=download&id=' + file_id\n",
    "    url = requests.get(dwn_url).text\n",
    "    books_raw = StringIO(url)\n",
    "    books = pd.read_csv(books_raw,names=colnames)\n",
    "elif curr_comp == 'sfort-laptop' or curr_comp == 'sfort-desktop':\n",
    "    books = pd.read_csv('toobig/books.csv',names=colnames)\n",
    "\n",
    "books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db1eea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in interactions data\n",
    "colnames = ['user_id','book_id','is_read','rating']\n",
    "\n",
    "if curr_comp == 'DESKTOP-ARTEMI5':\n",
    "    interactions = pd.read_csv('C:\\\\DSCI478_Project_Files\\\\interactions.csv',names=colnames)\n",
    "elif curr_comp == 'Mandey-Lappy-Toppy':\n",
    "    interactions = pd.read_csv('C:\\\\Users\\HP\\\\Dropbox\\\\000000 CSU\\\\CSU 2022 Spring\\\\DSCI 478\\\\Final Project\\\\interactions.csv',names=colnames)\n",
    "elif curr_comp == 'sfort-laptop' or curr_comp == 'sfort-desktop':\n",
    "    interactions = pd.read_csv('toobig/interactions.csv',names=colnames)\n",
    "\n",
    "# Isolate interactions with non-zero rating and is_read status\n",
    "interactions = interactions[interactions['is_read']==True]\n",
    "interactions = interactions[interactions['rating']!=0]\n",
    "interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5ac420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove books with no interactions\n",
    "unique_books_int = interactions.book_id.unique()\n",
    "for book in books.book_id:\n",
    "    if book not in unique_books_int:\n",
    "        books = books[books.book_id != book]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5ffe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CSV from reduced book set\n",
    "books.to_csv('red_books.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd69c4b0",
   "metadata": {},
   "source": [
    "# Sparse Matrix\n",
    "\n",
    "Coordinate sparse matrix encoding works by storing the row index, column index, and data value for each non-zero entry in the matrix. We need to map each `user_id` to a row in our sparse matrix, and each `book_id` to a column in our sparse matrix. So we create a map from unique `user_id`s to integers, and another map from each `book_id` to integers. Then we apply this map and build a sparse matrix from coordinate encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1be6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map between user_ids and index\n",
    "unique_users = np.array(interactions.user_id.unique())\n",
    "user_index = np.array(range(len(unique_users)))\n",
    "user_map = dict(zip(unique_users,user_index))\n",
    "\n",
    "# Map between book_ids and index\n",
    "book_ids = np.array(books.book_id)\n",
    "book_index = np.array(range(len(book_ids)))\n",
    "book_map = dict(zip(book_ids,book_index))\n",
    "\n",
    "# Apply maps to interactions set\n",
    "row = npi.remap(interactions.user_id, list(user_map.keys()), list(user_map.values()))\n",
    "col = npi.remap(interactions.book_id, list(book_map.keys()), list(book_map.values()))\n",
    "dat = np.array(interactions.rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f6000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sparse matrix in coordinate format\n",
    "users_size = unique_users.size\n",
    "books_size = book_ids.size\n",
    "users = coo_matrix((dat, (row,col)), shape=(users_size,books_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788f515b",
   "metadata": {},
   "source": [
    "# Creating CSV\n",
    "\n",
    "We need our recommendation system to have no dependence on the original datasets since they are quite large. Therefore we need to make a smaller dataset which carries over all necessary information while being smaller. We can take the coordinate/data pairs used in constructing our COO matrix, and put them into a CSV. We also need to store `book_id`s in order to recreate the bijection defined earlier purely from the data, but `book_id`s is part of the `books.csv` dataset, which is small enough to be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f80d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataframe of col, row, dat, unique_users, book_ids\n",
    "users_sparse_df = pd.DataFrame(list(zip(row,col,dat)),\n",
    "                              columns=['r_index','c_index','data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa3d35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "users_sparse_df.to_csv('users_sparse.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
